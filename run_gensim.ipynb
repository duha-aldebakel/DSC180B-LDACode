{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbc7f550-00cb-443b-8c99-35af1d308ff8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jorda\\anaconda3\\envs\\WH\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "import spacy\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "import pickle\n",
    "import bz2\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39e7a97f-bab7-4e30-93f0-b2d9d9a51f85",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style> .jp-Button path { fill: #616161;} text.terms { fill: #616161;} .jp-icon-warn0 path {fill: var(--jp-warn-color0);} .bp3-button-text path { fill: var(--jp-inverse-layout-color3);} .jp-icon-brand0 path { fill: var(--jp-brand-color0);} text.terms { fill: #616161;} </style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Bug fix for pyLDAvis https://github.com/bmabey/pyLDAvis/issues/162\n",
    "from IPython.display import HTML\n",
    "css_str = '<style> \\\n",
    ".jp-Button path { fill: #616161;} \\\n",
    "text.terms { fill: #616161;} \\\n",
    ".jp-icon-warn0 path {fill: var(--jp-warn-color0);} \\\n",
    ".bp3-button-text path { fill: var(--jp-inverse-layout-color3);} \\\n",
    ".jp-icon-brand0 path { fill: var(--jp-brand-color0);} \\\n",
    "text.terms { fill: #616161;} \\\n",
    "</style>'\n",
    "display(HTML(css_str ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7853834-d416-4c87-8732-6dfe2c706292",
   "metadata": {},
   "source": [
    "# Load datapickle \n",
    "From wikidownloader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9062c8c-3c19-4492-804e-11c57fa56f3a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jorda\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#python -m spacy download en_core_web_sm\n",
    "#python -m spacy download en_core_web_md\n",
    "import nltk;\n",
    "nltk.download('stopwords')\n",
    "nlp = spacy.load('en_core_web_md', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6eee80fa-7aee-4cd0-872a-1f2f21c27cbb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load data pickle\n",
      "Loaded data pickle\n"
     ]
    }
   ],
   "source": [
    "print('Load data pickle')\n",
    "with bz2.BZ2File('datapickle.bz2', 'rb') as f:  #Use datacompression BZ2\n",
    "    data= pickle.load(f)\n",
    "print('Loaded data pickle')\n",
    "    \n",
    "df=pd.DataFrame({'text':data[0],'title':data[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b4428beb-5d8e-4a54-8c55-35ea17a8c598",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'''Colonel Patrick Mackellar''' (1717–1778)...</td>\n",
       "      <td>Patrick_MacKellar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'''Putative ATP-dependent RNA helicase DHX57'...</td>\n",
       "      <td>DHX57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'''Abram Wesley Eager''' (1864 ndash;1930) was...</td>\n",
       "      <td>Abraham_Wesley_Eager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'''Babiuk''' is a surname. Notable people with...</td>\n",
       "      <td>Babiuk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>}} '''Surabaya–Gempol Toll Road''' is a to...</td>\n",
       "      <td>Surabaya%E2%80%93Gempol_Toll_Road</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>}.svg ---&amp;gt; |image_coat             = Wappe...</td>\n",
       "      <td>March_of_Lusatia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50000</th>\n",
       "      <td>In association football, rugby league, rugby u...</td>\n",
       "      <td>Dummy_(football)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50001</th>\n",
       "      <td>| status = complete | start_date = 1979 | co...</td>\n",
       "      <td>Shinjuku_NS_Building</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50002</th>\n",
       "      <td>The '''Wesleyan Methodist Church''' (also nam...</td>\n",
       "      <td>Wesleyan_Methodist_Church_(Great_Britain)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50003</th>\n",
       "      <td>|unitary_scotland= Angus  |lieutenancy_sco...</td>\n",
       "      <td>Woodhill,_Angus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50004 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  \\\n",
       "0         '''Colonel Patrick Mackellar''' (1717–1778)...   \n",
       "1       '''Putative ATP-dependent RNA helicase DHX57'...   \n",
       "2      '''Abram Wesley Eager''' (1864 ndash;1930) was...   \n",
       "3      '''Babiuk''' is a surname. Notable people with...   \n",
       "4          }} '''Surabaya–Gempol Toll Road''' is a to...   \n",
       "...                                                  ...   \n",
       "49999   }.svg ---&gt; |image_coat             = Wappe...   \n",
       "50000  In association football, rugby league, rugby u...   \n",
       "50001    | status = complete | start_date = 1979 | co...   \n",
       "50002   The '''Wesleyan Methodist Church''' (also nam...   \n",
       "50003      |unitary_scotland= Angus  |lieutenancy_sco...   \n",
       "\n",
       "                                           title  \n",
       "0                              Patrick_MacKellar  \n",
       "1                                          DHX57  \n",
       "2                           Abraham_Wesley_Eager  \n",
       "3                                         Babiuk  \n",
       "4              Surabaya%E2%80%93Gempol_Toll_Road  \n",
       "...                                          ...  \n",
       "49999                           March_of_Lusatia  \n",
       "50000                           Dummy_(football)  \n",
       "50001                       Shinjuku_NS_Building  \n",
       "50002  Wesleyan_Methodist_Church_(Great_Britain)  \n",
       "50003                            Woodhill,_Angus  \n",
       "\n",
       "[50004 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a48c2e-cf7c-4419-bde4-cdb64c60cdba",
   "metadata": {},
   "source": [
    "# Tokenizing articles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f5f0fc2-3dda-42e8-adb7-55ba75df6a8e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "   for sentence in sentences:\n",
    "      yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "data_words = list(sent_to_words(df.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6d0002ed-91f0-482b-a600-bd50f349d0f2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   '''Colonel Patrick Mackellar''' (1717–1778) was a British army officer and military engineer who played a significant role in the early history of North America.  He was the deputy chief engineer at the Siege of Louisbourg (1758) and the chief engineer at the siege of Quebec in 1759.  In later years he was responsible for the design and construction of the town of Es Castell on the island of Me\n"
     ]
    }
   ],
   "source": [
    "print(df.text[0][:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cb3b35a5-9931-4295-a7bb-42d1afa9e414",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['colonel', 'patrick', 'mackellar', 'was', 'british', 'army', 'officer', 'and', 'military', 'engineer', 'who', 'played', 'significant', 'role', 'in', 'the', 'early', 'history', 'of', 'north', 'america', 'he', 'was', 'the', 'deputy', 'chief', 'engineer', 'at', 'the', 'siege', 'of', 'louisbourg', 'and', 'the', 'chief', 'engineer', 'at', 'the', 'siege', 'of']\n"
     ]
    }
   ],
   "source": [
    "print(data_words[0][:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f553df0-e499-430f-811e-3e8b1dc23dab",
   "metadata": {},
   "source": [
    "# Removing stop words and adding bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df92497a-8640-4963-a515-4e51eddc7f00",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100)\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "def remove_stopwords(texts):\n",
    "   return [[word for word in simple_preprocess(str(doc)) \n",
    "   if word not in stop_words] for doc in texts]\n",
    "def make_bigrams(texts):\n",
    "   return [bigram_mod[doc] for doc in texts]\n",
    "def make_trigrams(texts):\n",
    "   [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "   texts_out = []\n",
    "   for sent in texts:\n",
    "      doc = nlp(\" \".join(sent))\n",
    "      texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "   return texts_out\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8f2ca521-6b23-4221-b274-451792192233",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['colonel', 'patrick', 'mackellar', 'british', 'army', 'officer', 'military', 'engineer', 'played', 'significant', 'role', 'early', 'history', 'north', 'america', 'deputy', 'chief', 'engineer', 'siege', 'louisbourg', 'chief', 'engineer', 'siege', 'quebec', 'later', 'years', 'responsible', 'design', 'construction', 'town', 'es', 'castell', 'island', 'menorca', 'early', 'life', 'career', 'patrick', 'mackellar', 'born']\n"
     ]
    }
   ],
   "source": [
    "print(data_words_nostops[0][:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5194ffcb-0b02-44d0-9057-56a8a9d96cb1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['colonel', 'patrick', 'mackellar', 'british', 'army', 'officer', 'military', 'engineer', 'played', 'significant', 'role', 'early', 'history', 'north_america', 'deputy', 'chief', 'engineer', 'siege', 'louisbourg', 'chief', 'engineer', 'siege', 'quebec', 'later', 'years', 'responsible', 'design', 'construction', 'town', 'es', 'castell', 'island', 'menorca', 'early', 'life', 'career', 'patrick', 'mackellar', 'born', 'son']\n"
     ]
    }
   ],
   "source": [
    "print(data_words_bigrams[0][:40])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86cd40b5-bb20-4dce-bc49-a57840cb70f6",
   "metadata": {},
   "source": [
    "# Lemmatization\n",
    "\n",
    "Reference: https://www.researchgate.net/publication/341574872_Machine_Learning_and_Deep_Neural_Network-Based_Lemmatization_and_Morphosyntactic_Tagging_for_Serbian\n",
    "\n",
    "\n",
    "The basic set of PoS-categories/tags that should be as-signed to tokens is not generally accepted, even for a spe-ciﬁc language. The choice of a tagset usually depends onthe foreseen task or project. A tagset tailored to be ap-plicable for PoS-tagging in general is the Universal Part-of-Speech (UPoS) tagset (Petrov et al., 2012) (used byspaCy), and it lists the following 17 categories: adjective(ADJ), adposition (ADP), adverb (ADV), auxiliary (AUX),coordinating conjunction (CCONJ), determiner (DET), in-terjection (INTJ), noun (N), numerical (NUM), particle(PART), pronoun (PRON), proper noun (PROPN), punctu-ation (PUNCT), subordinating conjunction (SCONJ), sym-bol (SYM), verb (VERB) and other (X). It should be notedthat the MULTEXT-East tagset (Erjavec, 2012) was alsotailored to be universal. SMD uses its own tagset thatcorresponds closely to Serbian traditional grammars. TheSerbian TreeTagger models TT11 and TT19 (see Subsec-tion 3.3.) use modiﬁcations of the SMD tagset. A gen-eral overview of the tagsets used is presented in Table 3.It should be noted that tags for some PoS differ betweentagsets (e.g. ADJ in UPoS vs. A in SMD for adjective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8e8cb768-09af-4f02-810f-982825c2835c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "doc=nlp(\" \".join(data_words_bigrams[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97f91eda-31a7-48ab-8bd4-afe509a15cea",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lemmatization Example colonel -> PROPN\n",
      "Lemmatization Example officer -> NOUN\n",
      "Lemmatization Example military -> ADJ\n",
      "Lemmatization Example play -> VERB\n",
      "Lemmatization Example later -> ADV\n",
      "Lemmatization Example maam -> INTJ\n",
      "Lemmatization Example four -> NUM\n",
      "Lemmatization Example along -> ADP\n",
      "Lemmatization Example may -> AUX\n",
      "Lemmatization Example upon -> SCONJ\n",
      "Lemmatization Example th -> X\n",
      "Lemmatization Example another -> DET\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['PROPN',\n",
       " 'NOUN',\n",
       " 'ADJ',\n",
       " 'VERB',\n",
       " 'ADV',\n",
       " 'INTJ',\n",
       " 'NUM',\n",
       " 'ADP',\n",
       " 'AUX',\n",
       " 'SCONJ',\n",
       " 'X',\n",
       " 'DET']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags=[]\n",
    "for w in doc:\n",
    "    if not w.pos_ in tags:\n",
    "        print('Lemmatization Example {} -> {}'.format(w.lemma_,w.pos_))\n",
    "        tags.append(w.pos_)\n",
    "tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01af11e5-4038-4ea9-8c05-750501065109",
   "metadata": {},
   "source": [
    "We will only keep the UPoS with the following tags 'NOUN', 'ADJ', 'VERB', 'ADV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c39e5b1b-f6bb-479d-a2f0-332e6cdaafa6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['british', 'officer', 'military', 'engineer', 'play', 'significant', 'role', 'early', 'history', 'deputy', 'chief', 'engineer', 'siege', 'chief', 'engineer', 'siege', 'quebec', 'later', 'year', 'responsible', 'design', 'construction', 'town', 'menorca', 'early', 'life', 'career', 'bear', 'son', 'tenant', 'maam', 'argyllshire', 'probably', 'influence', 'second', 'duke', 'argyll', 'enter', 'ordnance', 'service']\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=[\n",
    "   'NOUN', 'ADJ', 'VERB', 'ADV'\n",
    "])\n",
    "print(data_lemmatized[0][:40]) #it will print the lemmatized data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f137597f-42f1-4358-8f64-fa5785b3d510",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['colonel', 'patrick', 'mackellar', 'british', 'army', 'officer', 'military', 'engineer', 'played', 'significant', 'role', 'early', 'history', 'north_america', 'deputy', 'chief', 'engineer', 'siege', 'louisbourg', 'chief', 'engineer', 'siege', 'quebec', 'later', 'years', 'responsible', 'design', 'construction', 'town', 'es', 'castell', 'island', 'menorca', 'early', 'life', 'career', 'patrick', 'mackellar', 'born', 'son', 'john', 'last', 'mackellar', 'head', 'tenant', 'maam', 'argyllshire', 'probably', 'influence', 'second', 'duke', 'argyll', 'entered', 'ordnance', 'service']\n"
     ]
    }
   ],
   "source": [
    "print(data_words_bigrams[0][:55])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a8618b-811c-45ef-8d47-3130a8ca91c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Creating bag of words frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa94cf9-0746-4faf-8df1-a96daf9ba435",
   "metadata": {},
   "source": [
    "Without Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d918be76-7e50-40ea-b8d6-105d8c4ef596",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2), (1, 1), (2, 2), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 2), (17, 3), (18, 1), (19, 1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('able', 2),\n",
       " ('abraham', 1),\n",
       " ('accompanied', 2),\n",
       " ('accompany', 1),\n",
       " ('accounts', 1),\n",
       " ('acting', 1),\n",
       " ('action', 1),\n",
       " ('active', 1),\n",
       " ('admiral', 1),\n",
       " ('advised', 1),\n",
       " ('advisers', 1),\n",
       " ('afternoon', 1),\n",
       " ('agent', 1),\n",
       " ('al', 1),\n",
       " ('allies', 1),\n",
       " ('along', 1),\n",
       " ('also', 2),\n",
       " ('although', 3),\n",
       " ('amara', 1),\n",
       " ('america', 1)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word = corpora.Dictionary(data_words_bigrams)\n",
    "texts = data_words_bigrams\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "print(corpus[0][:20]) #it will print the corpus we created above.\n",
    "[(id2word[id], freq) for id, freq in corpus[0]][:20]\n",
    "#it will print the words with their frequencies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69de9ba-aa19-4575-bf26-bb666ea1fd26",
   "metadata": {},
   "source": [
    "With Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4aa6c205-fd1e-4ac4-9958-560a176062bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 2), (1, 3), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1), (9, 1), (10, 1), (11, 2), (12, 3), (13, 4), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 5)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('able', 2),\n",
       " ('accompany', 3),\n",
       " ('account', 1),\n",
       " ('act', 1),\n",
       " ('action', 1),\n",
       " ('active', 1),\n",
       " ('admiral', 1),\n",
       " ('advise', 1),\n",
       " ('adviser', 1),\n",
       " ('agent', 1),\n",
       " ('ally', 1),\n",
       " ('also', 2),\n",
       " ('appear', 3),\n",
       " ('appoint', 4),\n",
       " ('appointment', 1),\n",
       " ('approach', 1),\n",
       " ('aptitude', 1),\n",
       " ('argyll', 1),\n",
       " ('argyllshire', 1),\n",
       " ('army', 5)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word_lemmatized = corpora.Dictionary(data_lemmatized)\n",
    "texts_lemmatized = data_lemmatized\n",
    "corpus_lemmatized = [id2word_lemmatized.doc2bow(text) for text in texts_lemmatized]\n",
    "print(corpus_lemmatized[0][:20]) #it will print the corpus we created above.\n",
    "[(id2word_lemmatized[id], freq) for id, freq in corpus_lemmatized[0]][:20]\n",
    "#it will print the words with their frequencies.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71e8378-5961-497a-a753-d83b637210b2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fitting via LDA Variational Inference (Gensim) library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c5f623-57a9-4d28-8fb0-217ea62c171b",
   "metadata": {},
   "source": [
    "Without Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "47917a7e-f726-4b82-84b4-fc14ce38a280",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lda_model = gensim.models.ldamodel.LdaModel(\n",
    "   corpus=corpus, id2word=id2word, num_topics=20, random_state=100, \n",
    "   update_every=1, chunksize=100, passes=5, alpha='auto', per_word_topics=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "140ac093-53d7-4a2a-a706-da3b108e6cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -17.878707601854718\n",
      "\n",
      "Coherence Score:  0.5764669129992225\n"
     ]
    }
   ],
   "source": [
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))\n",
    "coherence_model_lda = CoherenceModel(\n",
    "   model=lda_model, texts=texts, dictionary=id2word, coherence='c_v'\n",
    ")\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcc54cc-03a2-4b80-b73a-160adddfbff5",
   "metadata": {},
   "source": [
    "With Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9dceb2-7413-4259-a739-0d0afcc8a84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_lemmatized = gensim.models.ldamodel.LdaModel(\n",
    "   corpus=corpus_lemmatized, id2word=id2word_lemmatized, num_topics=20, random_state=100, \n",
    "   update_every=1, chunksize=100, passes=5, alpha='auto', per_word_topics=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbb5dbc-d97f-4e2c-ad62-50fd525aaa78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nPerplexity: ', lda_model_lemmatized.log_perplexity(corpus_lemmatized))\n",
    "coherence_model_lda_lemmatized = CoherenceModel(\n",
    "   model=lda_model_lemmatized, texts=texts_lemmatized, dictionary=id2word_lemmatized, coherence='c_v'\n",
    ")\n",
    "coherence_lda_lemmatized = coherence_model_lda_lemmatized.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda_lemmatized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faaaf4a-86eb-4e8d-a80f-bf5329f4ade9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f0fb16a2-6b30-42ed-9903-ca6c47140b57",
   "metadata": {},
   "source": [
    "# Exploring final model (with Lemmatization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063bdbc6-de67-4abf-8ba7-07c2160f0552",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pprint(lda_model_lemmatized.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3740515-f71c-4e00-99d6-bfe8c329f59e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = gensimvis.prepare(lda_model_lemmatized, corpus_lemmatized, id2word_lemmatized)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3236e0-7cd2-4e88-9119-cb25c68be8d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WH",
   "language": "python",
   "name": "wh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
